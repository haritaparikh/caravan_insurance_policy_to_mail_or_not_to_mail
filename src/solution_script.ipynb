{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"data/processed_data/x_train.csv\")\n",
    "x_val = pd.read_csv(\"data/processed_data/x_val.csv\")\n",
    "y_train = pd.read_csv(\"data/processed_data/y_train.csv\")\n",
    "y_val = pd.read_csv(\"data/processed_data/y_val.csv\")\n",
    "x_test = pd.read_csv(\"data/processed_data/x_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing the train dataset by upsampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CARAVAN Number of mobile home policies\n",
       "0.0                                       4390\n",
       "1.0                                        267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine x and y train datasets\n",
    "train_data = pd.concat([x_train, y_train], axis=1)\n",
    "# Separate majority and minority classes\n",
    "df_majority = train_data[train_data[\"CARAVAN Number of mobile home policies\"]==0]\n",
    "df_minority = train_data[train_data[\"CARAVAN Number of mobile home policies\"]==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,    # sample without replacement \n",
    "                                 n_samples=1000,   # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_upsampled = pd.concat([df_minority_upsampled, df_majority])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled[\"CARAVAN Number of mobile home policies\"].value_counts()\n",
    "\n",
    "# Splitting df_downsampled into x and y\n",
    "target ='CARAVAN Number of mobile home policies'\n",
    "x_train = df_upsampled.drop([target],1)\n",
    "y_train = df_upsampled[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [2, 5, None],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'n_estimators':[100, 500, 1000],\n",
    "          'min_samples_split':[2, 5, None],\n",
    "          'min_samples_leaf':[1,10,100]}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "rf_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='f1')\n",
    "\n",
    "rf_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 0.3104359313077939\n",
      "roc_auc_score: 0.6479203680925698\n",
      "confusion_matrix: \n",
      " [[698 386]\n",
      " [ 34  47]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.64      0.77      1084\n",
      "         1.0       0.11      0.58      0.18        81\n",
      "\n",
      "    accuracy                           0.64      1165\n",
      "   macro avg       0.53      0.61      0.48      1165\n",
      "weighted avg       0.89      0.64      0.73      1165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on training dataset\n",
    "predicted_train = rf_model.predict_proba(x_train)[:,1]\n",
    "actual = y_train.values.ravel()\n",
    "\n",
    "# fbetas statistic \n",
    "\n",
    "cutoffs = np.linspace(0.001,0.999,999)\n",
    "fbetas=[]\n",
    "for cutoff in cutoffs:    \n",
    "    predicted=(predicted_train>cutoff).astype(int)  \n",
    "    fbetas.append(fbeta_score(actual, predicted, beta=2))\n",
    "    \n",
    "# list(zip(cutoffs,KS_all))\n",
    "\n",
    "cutoff_optimum = cutoffs[fbetas == max(fbetas)][0]\n",
    "predicted_val = rf_model.predict_proba(x_val)[:,1]\n",
    "\n",
    "val_classes = (predicted_val>cutoff_optimum).astype(int)\n",
    "# pd.Series(val_classes).value_counts()\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, predicted_val)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    732\n",
       "1    433\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(val_classes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.001],\n",
       "                         'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [5, 10],\n",
       "                         'n_estimators': [100, 500], 'tol': [0.001, 0.0001]},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model development\n",
    "\n",
    "params = {'n_estimators':[100, 500],\n",
    "        'learning_rate':[0.01, 0.001],\n",
    "        'min_samples_leaf':[1,10,100],\n",
    "        'min_samples_split': [5, 10],\n",
    "         'tol': [0.001, 0.0001]}\n",
    "\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "gb_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='f1')\n",
    "gb_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 0.3895274584929757\n",
      "roc_auc_score: 0.7776638877499886\n",
      "confusion_matrix: \n",
      " [[686 398]\n",
      " [ 20  61]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.63      0.77      1084\n",
      "         1.0       0.13      0.75      0.23        81\n",
      "\n",
      "    accuracy                           0.64      1165\n",
      "   macro avg       0.55      0.69      0.50      1165\n",
      "weighted avg       0.91      0.64      0.73      1165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on training dataset\n",
    "predicted_train = gb_model.predict_proba(x_train)[:,1]\n",
    "actual = y_train.values.ravel()\n",
    "\n",
    "# fbetas statistic \n",
    "\n",
    "cutoffs = np.linspace(0.001,0.999,999)\n",
    "fbetas=[]\n",
    "for cutoff in cutoffs:    \n",
    "    predicted=(predicted_train>cutoff).astype(int)  \n",
    "    fbetas.append(fbeta_score(actual, predicted, beta=2))\n",
    "    \n",
    "# list(zip(cutoffs,KS_all))\n",
    "\n",
    "cutoff_optimum = cutoffs[fbetas == max(fbetas)][0]\n",
    "predicted_val = gb_model.predict_proba(x_val)[:,1]\n",
    "\n",
    "val_classes = (predicted_val>cutoff_optimum).astype(int)\n",
    "# pd.Series(val_classes).value_counts()\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, predicted_val)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    706\n",
       "1    459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(val_classes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 984 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1236 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1632 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2100 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2640 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3252 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3936 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([ 0.01      ,  0.11090909,  0.21181818,  0.31272727,  0.41363636,\n",
       "        0.51454545,  0.61545455,  0.71636364,  0.81727273,  0.91818182,\n",
       "        1.01909091,  1.12      ,  1.22090909,  1.32181818,  1.42272727,\n",
       "        1.52363636,  1.62454545,  1.72545455,  1.82636364,  1.92727273,\n",
       "        2.02818182,  2.12909091,  2.23      ,  2.33090909,  2.43181818,\n",
       "        2.53272727...\n",
       "        7.07363636,  7.17454545,  7.27545455,  7.37636364,  7.47727273,\n",
       "        7.57818182,  7.67909091,  7.78      ,  7.88090909,  7.98181818,\n",
       "        8.08272727,  8.18363636,  8.28454545,  8.38545455,  8.48636364,\n",
       "        8.58727273,  8.68818182,  8.78909091,  8.89      ,  8.99090909,\n",
       "        9.09181818,  9.19272727,  9.29363636,  9.39454545,  9.49545455,\n",
       "        9.59636364,  9.69727273,  9.79818182,  9.89909091, 10.        ]),\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# model development\n",
    "\n",
    "params = {'penalty':['l1','l2'],\n",
    "          'class_weight':['balanced', None],\n",
    "          'C':np.linspace(0.01,10,100)}\n",
    "model = LogisticRegression()\n",
    "\n",
    "lr_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='f1')\n",
    "\n",
    "lr_model.fit(x_train_scaled, \n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 0.3931924882629109\n",
      "roc_auc_score: 0.7650733451778963\n",
      "confusion_matrix: \n",
      " [[623 461]\n",
      " [ 14  67]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.57      0.72      1084\n",
      "         1.0       0.13      0.83      0.22        81\n",
      "\n",
      "    accuracy                           0.59      1165\n",
      "   macro avg       0.55      0.70      0.47      1165\n",
      "weighted avg       0.92      0.59      0.69      1165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on training dataset\n",
    "predicted_train = lr_model.predict_proba(x_train_scaled)[:,1]\n",
    "actual = y_train.values.ravel()\n",
    "\n",
    "# fbetas statistic \n",
    "\n",
    "cutoffs = np.linspace(0.001,0.999,999)\n",
    "fbetas=[]\n",
    "for cutoff in cutoffs:    \n",
    "    predicted=(predicted_train>cutoff).astype(int)  \n",
    "    fbetas.append(fbeta_score(actual, predicted, beta=2))\n",
    "    \n",
    "# list(zip(cutoffs,KS_all))\n",
    "\n",
    "cutoff_optimum = cutoffs[fbetas == max(fbetas)][0]\n",
    "predicted_val = lr_model.predict_proba(x_val_scaled)[:,1]\n",
    "\n",
    "val_classes = (predicted_val>cutoff_optimum).astype(int)\n",
    "# pd.Series(val_classes).value_counts()\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, predicted_val)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   38.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDClassifier(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 1e-05],\n",
       "                         'max_iter': [500, 1000, 1500], 'penalty': ['l1', 'l2'],\n",
       "                         'tol': [0.001, 0.0001]},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# model development\n",
    "\n",
    "params = {'penalty':['l1','l2'],\n",
    "          'tol':[0.001, 0.0001],\n",
    "          'alpha': [0.0001, 0.00001],\n",
    "         'max_iter': [500, 1000, 1500]}\n",
    "\n",
    "model = SGDClassifier(loss='hinge')\n",
    "\n",
    "svm_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='f1')\n",
    "svm_model.fit(x_train_scaled, \n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Train***********\n",
      "fbeta: 0.17458100558659218\n",
      "roc_auc_score: 0.558371298405467\n",
      "confusion_matrix: \n",
      " [[4244  146]\n",
      " [ 850  150]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.97      0.89      4390\n",
      "         1.0       0.51      0.15      0.23      1000\n",
      "\n",
      "    accuracy                           0.82      5390\n",
      "   macro avg       0.67      0.56      0.56      5390\n",
      "weighted avg       0.77      0.82      0.77      5390\n",
      "\n",
      "**********Validation***********\n",
      "fbeta: 0.08356545961002786\n",
      "roc_auc_score: 0.5236606532731993\n",
      "confusion_matrix: \n",
      " [[1055   29]\n",
      " [  75    6]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95      1084\n",
      "         1.0       0.17      0.07      0.10        81\n",
      "\n",
      "    accuracy                           0.91      1165\n",
      "   macro avg       0.55      0.52      0.53      1165\n",
      "weighted avg       0.88      0.91      0.89      1165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on validation dataset\n",
    "train_classes = svm_model.predict(x_train_scaled)\n",
    "\n",
    "fbeta=fbeta_score(y_train, \n",
    "                 train_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_train, \n",
    "                     train_classes)\n",
    "class_report = classification_report(y_train, \n",
    "                                    train_classes)\n",
    "\n",
    "print(\"**********Train***********\")\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_train, train_classes)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n",
    "\n",
    "# prediction on validation dataset\n",
    "\n",
    "val_classes = svm_model.predict(x_val_scaled)\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"**********Validation***********\")\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, val_classes)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.1min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={'max_iter': [500, 1000, 1500], 'tol': [0.0001, 1e-05]},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# model development\n",
    "\n",
    "params = {'tol':[0.0001, 0.00001],\n",
    "         'max_iter': [500, 1000, 1500]}\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "svc_svm_model = GridSearchCV(model,\n",
    "                            cv=10,\n",
    "                            param_grid=params,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5,\n",
    "                            scoring='f1')\n",
    "svc_svm_model.fit(x_train_scaled, \n",
    "                  y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Train***********\n",
      "fbeta: 0.20248127340823968\n",
      "roc_auc_score: 0.5752243735763098\n",
      "confusion_matrix: \n",
      " [[4291   99]\n",
      " [ 827  173]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.98      0.90      4390\n",
      "         1.0       0.64      0.17      0.27      1000\n",
      "\n",
      "    accuracy                           0.83      5390\n",
      "   macro avg       0.74      0.58      0.59      5390\n",
      "weighted avg       0.80      0.83      0.79      5390\n",
      "\n",
      "**********Validation***********\n",
      "fbeta: 0.07122507122507121\n",
      "roc_auc_score: 0.5207165960548495\n",
      "confusion_matrix: \n",
      " [[1062   22]\n",
      " [  76    5]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.96      1084\n",
      "         1.0       0.19      0.06      0.09        81\n",
      "\n",
      "    accuracy                           0.92      1165\n",
      "   macro avg       0.56      0.52      0.52      1165\n",
      "weighted avg       0.88      0.92      0.90      1165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on validation dataset\n",
    "train_classes = svc_svm_model.predict(x_train_scaled)\n",
    "\n",
    "fbeta=fbeta_score(y_train, \n",
    "                 train_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_train, \n",
    "                     train_classes)\n",
    "class_report = classification_report(y_train, \n",
    "                                    train_classes)\n",
    "\n",
    "print(\"**********Train***********\")\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_train, train_classes)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n",
    "\n",
    "# prediction on validation dataset\n",
    "\n",
    "val_classes = svc_svm_model.predict(x_val_scaled)\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"**********Validation***********\")\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, val_classes)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 14.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 462 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 700 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1024 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1420 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1888 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2428 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3040 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3656 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 11.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 11.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1724 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2192 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2732 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3344 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3993 out of 4000 | elapsed:  3.9min remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 912 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1232 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1628 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2096 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2636 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3248 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3932 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  4.0min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1071 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1724 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2192 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2732 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3344 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3993 out of 4000 | elapsed:  3.9min remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1416 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1812 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2820 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3432 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1364 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1760 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2228 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2768 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3380 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2112 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3408 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:   33.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('gb',\n",
       "                                GridSearchCV(cv=10,\n",
       "                                             estimator=GradientBoostingClassifier(),\n",
       "                                             n_jobs=-1,\n",
       "                                             param_grid={'learning_rate': [0.01,\n",
       "                                                                           0.001],\n",
       "                                                         'min_samples_leaf': [1,\n",
       "                                                                              10,\n",
       "                                                                              100],\n",
       "                                                         'min_samples_split': [5,\n",
       "                                                                               10],\n",
       "                                                         'n_estimators': [100,\n",
       "                                                                          500],\n",
       "                                                         'tol': [0.001,\n",
       "                                                                 0.0001]},\n",
       "                                             scoring='f1', verbose=5)),\n",
       "                               ('lr',\n",
       "                                GridSearchCV(cv=10,\n",
       "                                             estimator=LogisticRegression(),\n",
       "                                             n_jobs=-1,\n",
       "                                             param_gri...\n",
       "        7.07363636,  7.17454545,  7.27545455,  7.37636364,  7.47727273,\n",
       "        7.57818182,  7.67909091,  7.78      ,  7.88090909,  7.98181818,\n",
       "        8.08272727,  8.18363636,  8.28454545,  8.38545455,  8.48636364,\n",
       "        8.58727273,  8.68818182,  8.78909091,  8.89      ,  8.99090909,\n",
       "        9.09181818,  9.19272727,  9.29363636,  9.39454545,  9.49545455,\n",
       "        9.59636364,  9.69727273,  9.79818182,  9.89909091, 10.        ]),\n",
       "                                                            'class_weight': ['balanced',\n",
       "                                                                             None],\n",
       "                                                            'penalty': ['l1',\n",
       "                                                                        'l2']},\n",
       "                                                scoring='f1', verbose=5))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [('gb', gb_model),\n",
    "             ('lr', lr_model)]\n",
    "final_estimator = lr_model\n",
    "              \n",
    "stacking_model = StackingClassifier(estimators = estimators, \n",
    "                                  final_estimator = final_estimator)\n",
    "stacking_model.fit(x_train,\n",
    "                   y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 0.40045766590389004\n",
      "roc_auc_score: 0.7663830804974716\n",
      "confusion_matrix: \n",
      " [[604 480]\n",
      " [ 11  70]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.56      0.71      1084\n",
      "         1.0       0.13      0.86      0.22        81\n",
      "\n",
      "    accuracy                           0.58      1165\n",
      "   macro avg       0.55      0.71      0.47      1165\n",
      "weighted avg       0.92      0.58      0.68      1165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on training dataset\n",
    "predicted_train = stacking_model.predict_proba(x_train_scaled)[:,1]\n",
    "actual = y_train.values.ravel()\n",
    "\n",
    "# fbetas statistic \n",
    "\n",
    "cutoffs = np.linspace(0.001,0.999,999)\n",
    "fbetas=[]\n",
    "for cutoff in cutoffs:    \n",
    "    predicted=(predicted_train>cutoff).astype(int)  \n",
    "    fbetas.append(fbeta_score(actual, predicted, beta=2))\n",
    "    \n",
    "# list(zip(cutoffs,KS_all))\n",
    "\n",
    "cutoff_optimum = cutoffs[fbetas == max(fbetas)][0]\n",
    "predicted_val = stacking_model.predict_proba(x_val_scaled)[:,1]\n",
    "\n",
    "val_classes = (predicted_val>cutoff_optimum).astype(int)\n",
    "# pd.Series(val_classes).value_counts()\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, predicted_val)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    615\n",
       "1    550\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(y_val).value_counts()\n",
    "# pd.Series(val_classes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final predictions using stacking model based on fbeta score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=(stacking_model.predict_proba(x_test)[:,1]>cutoff_optimum).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2268\n",
       "0    1732\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame({'V86':predictions})\n",
    "submissions.to_csv('output/prediction_submission_2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
